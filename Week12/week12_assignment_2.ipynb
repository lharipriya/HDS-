{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzJThPNv0AZ"
      },
      "source": [
        "# Week 11 Assignment\n",
        "\n",
        "\n",
        "Please do the programming exercise and verify that your code works using the tests, then think about your final project and fill out the questions in the second part.\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6UAso9Wv0Aa"
      },
      "source": [
        "### 47.1: Filtering and summarizing data\n",
        "\n",
        "For this work, you'll find a data file in `https://hds5210-data.s3.amazonaws.com/complications_all.csv`.\n",
        "\n",
        "Read in the data file and create a variable called `mo_hospitals` that contains a data frame from the `complications_all.csv` file, filtered down to only contain those hospitals from the state of Missouri (MO).\n",
        "\n",
        "Then aggregate that data by hospital into a variable named `mo_summary`.  There are some key fields that we want to summarize:\n",
        "* We want to know the earliest date that each hospital was participating in any program\n",
        "* We want to know the latest date that each hospital stopped participating in any program\n",
        "* We want to know the total number of patients in the denominators of these programs\n",
        "\n",
        "Some things to note:\n",
        "* You will need to convert the `Start Date` and `End Date` to actual datetime fields\n",
        "* You will need to clean up and convert the `Denominator` field to just be numeric - the rule that you should use it to simply remove any records where the `Denominator` is `'Not Available'`\n",
        "\n",
        "\n",
        "The final result of this step should be a new data frame called `mo_summary` that contains one row for each hospital and contains the min start date, max end date, and total denominator.  Use the names `start_date`, `end_date`, and `number` for those columns in `mo_summary`.\n",
        "\n",
        "\n",
        "You do not need to create your code in the form of a function, just make sure your variable names match what I've described above so the tests work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bjE6pWn1v0Ab"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# This is just to show you the name to use for the variable you need to create for this step to pass.\n",
        "all_hospitals = pd.read_csv('https://hds5210-data.s3.amazonaws.com/complications_all.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PUldODYMv0Ac",
        "outputId": "8ab41625-09fd-4fbf-cadf-52841915a70b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'State' column not found. Available columns: ['provider_id', 'hospital_name', 'address', 'city', 'state', 'zip_code', 'county_name', 'phone_number', 'measure_id', 'measure_name', 'compared_to_national', 'denominator', 'score', 'lower_estimate', 'higher_estimate', 'footnote', 'measure_start_date', 'measure_end_date']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV data\n",
        "data = pd.read_csv('/content/complications.csv')\n",
        "\n",
        "# Check if 'State' column exists, if not, print the available columns\n",
        "if 'State' not in data.columns:\n",
        "    print(f\"'State' column not found. Available columns: {data.columns.tolist()}\")\n",
        "    # Adjust the column name used for filtering based on available columns if needed\n",
        "    # Example: if 'Provider State' exists, update the filtering condition accordingly.\n",
        "else:\n",
        "    # Filter data for Missouri hospitals\n",
        "    mo_hospitals = data[data['State'] == 'MO'].copy()\n",
        "\n",
        "    # Convert 'Start Date' and 'End Date' columns to datetime\n",
        "    mo_hospitals['Start Date'] = pd.to_datetime(mo_hospitals['Start Date'], errors='coerce')\n",
        "    mo_hospitals['End Date'] = pd.to_datetime(mo_hospitals['End Date'], errors='coerce')\n",
        "\n",
        "    # Remove rows where Denominator is 'Not Available' and convert to numeric\n",
        "    mo_hospitals = mo_hospitals[mo_hospitals['Denominator'] != 'Not Available']\n",
        "    mo_hospitals['Denominator'] = pd.to_numeric(mo_hospitals['Denominator'], errors='coerce')\n",
        "\n",
        "    # Print success message or preview data (optional)\n",
        "    print(f\"Filtered data for hospitals in Missouri. Total records: {len(mo_hospitals)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'State' not in data.columns:\n",
        "    print(f\"'State' column not found. Available columns: {data.columns.tolist()}\")\n",
        "    # ...\n",
        "else:\n",
        "    # Filter data for Missouri hospitals\n",
        "    mo_hospitals = data[data['State'] == 'MO'].copy()\n",
        "    # ..."
      ],
      "metadata": {
        "id": "0K7VSJwtyBa0",
        "outputId": "dadf0b0c-8ebd-427a-fe0b-2c71ec9c6ae2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'State' column not found. Available columns: ['provider_id', 'hospital_name', 'address', 'city', 'state', 'zip_code', 'county_name', 'phone_number', 'measure_id', 'measure_name', 'compared_to_national', 'denominator', 'score', 'lower_estimate', 'higher_estimate', 'footnote', 'measure_start_date', 'measure_end_date']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "BmlUQPwMv0Ac",
        "outputId": "5fb6bc8e-c617-41c5-e662-7f6dba9011ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'mo_summary' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-59ba18c69dea>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assertions to validate the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mmo_summary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1766908\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Total sum of 'number' does not match expected value.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mmo_summary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2015\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Earliest start_date does not match expected value.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mmo_summary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2018\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Latest end_date does not match expected value.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mmo_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m108\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Shape of mo_summary does not match expected dimensions.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mo_summary' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "    # Assertions to validate the data\n",
        "    assert mo_summary['number'].sum() == 1766908, \"Total sum of 'number' does not match expected value.\"\n",
        "    assert mo_summary['start_date'].min() == pd.Timestamp(2015, 4, 1), \"Earliest start_date does not match expected value.\"\n",
        "    assert mo_summary['end_date'].max() == pd.Timestamp(2018, 6, 30), \"Latest end_date does not match expected value.\"\n",
        "    assert mo_summary.shape == (108, 3), \"Shape of mo_summary does not match expected dimensions.\"\n",
        "    assert mo_summary.loc['BARNES JEWISH HOSPITAL', 'number'] == 131313, \"Number for 'BARNES JEWISH HOSPITAL' does not match expected value.\"\n",
        "    assert mo_summary.loc['BOONE HOSPITAL CENTER', 'number'] == 63099, \"Number for 'BOONE HOSPITAL CENTER' does not match expected value.\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK3L1xmlv0Ac"
      },
      "source": [
        "---\n",
        "\n",
        "### 47.2 Planning your final project\n",
        "\n",
        "You should be thinking about the things we've been learning and how you can apply them to your final project.  Use the rubric to help guid your thinking and then answer the questions below.  This is meant as a guide to help you think through what you will do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GYpeSWlv0Ac"
      },
      "source": [
        "#### A) Data Access\n",
        "\n",
        "Your project should include data from at least three distinct types of sources.  For example: AWS S3, Relational Databases, Internet, Web Services, local files.  List what data sources you're planning to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN6n3XVov0Ac"
      },
      "source": [
        "To efficiently handle and analyze its datasets, the project uses a variety of data types. The CSV format, which is perfect for numerical and categorical data analysis, will be used to store the flow cytometry data from kidney experiments in humans and mice. To enable thorough visualization, immunohistochemical histological data will be stored as high-resolution picture files (such as JPEG, PNG, or TIFF). To provide organized and smooth connection with analysis tools, metadata and annotations such as patient/mouse IDs, experimental settings, and immune cell subset details will be captured in JSON or XML forms. Flexibility and scalability are offered by the combination of these formats: JSON/XML for metadata, picture files for histological analysis, and CSV for numerical data. This method supports strong analysis workflows by facilitating effective data storage, retrieval, and cross-platform interoperability.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCz8d27Nv0Ad"
      },
      "source": [
        "#### B. Data Formats\n",
        "\n",
        "Your project should include data that comes in different file formats.  For example: HL7, EDI, HTML, CSV, Excel, JSON, XML.  List what data formats you're planning to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZzxTCOtv0Ad"
      },
      "source": [
        "PLANNING TO TAKE CSV FILES OF DATA SET\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn7ipyhUv0Ad"
      },
      "source": [
        "#### C. Objective\n",
        "\n",
        "What purpose would your project serve in a real work setting?  Take a couple of paragraphs to write down why this is an interesting product."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrZv1nKrv0Ad"
      },
      "source": [
        "This project has significant implications in real-world settings, particularly in the fields of immunology, nephrology, and translational medicine. Understanding the immune cell landscape in human kidneys is crucial for advancing the diagnosis and treatment of kidney diseases. By comparing human kidney immune cell profiles to those of mouse models, the project bridges the gap between experimental findings in animals and their applicability to human health. This enhances the relevance and precision of preclinical studies, aiding in the development of new therapies for kidney-related conditions such as autoimmune diseases, infections, and transplant rejection.Additionally, the initiative is a base resource for individualized medication. It establishes a baseline for detecting anomalies in sick conditions by describing the makeup and activity of immune cells in healthy human kidneys. This information can be used to optimize current treatments or create tailored immunotherapies. A useful tool for academics and clinicians trying to better understand and treat renal illnesses, the integration of data from many sources and formats also guarantees that the methodology is reliable, scalable, and flexible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1HgV8XNv0Ae"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Submit your work via GitHub as normal\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}